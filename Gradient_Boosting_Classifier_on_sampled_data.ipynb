{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Aanisha/ACL_Abusive_Tamil_Comment_Classification/blob/main/Gradient_Boosting_Classifier_on_sampled_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w946rFQWXhNe"
   },
   "source": [
    "# Gradient Boosting Classifier on the dataset\n",
    "\n",
    "The experiment here uses the data after the oversampling and under-sampling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zUtblVESanq",
    "outputId": "3aa8ee08-d935-4e09-b6c2-5b481322adc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting indic-nlp-library\n",
      "  Obtaining dependency information for indic-nlp-library from https://files.pythonhosted.org/packages/ec/21/61240bcf965cedfec993497b38c42f054b149b9669e6d6cddeb1dee09d51/indic_nlp_library-0.92-py3-none-any.whl.metadata\n",
      "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting sphinx-argparse (from indic-nlp-library)\n",
      "  Obtaining dependency information for sphinx-argparse from https://files.pythonhosted.org/packages/21/98/d32f45b19b60e52b4ddc714dee139a92c6ea8fa9115f994884d321c3454d/sphinx_argparse-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
      "  Obtaining dependency information for sphinx-rtd-theme from https://files.pythonhosted.org/packages/ea/46/00fda84467815c29951a9c91e3ae7503c409ddad04373e7cfc78daad4300/sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting morfessor (from indic-nlp-library)\n",
      "  Obtaining dependency information for morfessor from https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl.metadata\n",
      "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
      "Requirement already satisfied: pandas in c:\\users\\waqar\\appdata\\roaming\\python\\python311\\site-packages (from indic-nlp-library) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from indic-nlp-library) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from pandas->indic-nlp-library) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from pandas->indic-nlp-library) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from pandas->indic-nlp-library) (2023.3)\n",
      "Requirement already satisfied: sphinx>=1.2.0 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx-argparse->indic-nlp-library) (5.0.2)\n",
      "Requirement already satisfied: docutils<0.21 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx-rtd-theme->indic-nlp-library) (0.18.1)\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
      "  Obtaining dependency information for sphinxcontrib-jquery<5,>=4 from https://files.pythonhosted.org/packages/76/85/749bd22d1a68db7291c89e2ebca53f4306c3f205853cf31e9de279034c3c/sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
      "Requirement already satisfied: Jinja2>=2.3 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.0 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.15.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.12)\n",
      "Requirement already satisfied: imagesize in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.5.0 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (23.1)\n",
      "Requirement already satisfied: colorama>=0.3.5 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\waqar\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2023.7.22)\n",
      "Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
      "   ---------------------------------------- 0.0/40.3 kB ? eta -:--:--\n",
      "   ------------------------------ --------- 30.7/40.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 40.3/40.3 kB 476.5 kB/s eta 0:00:00\n",
      "Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
      "Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.8 MB 2.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/2.8 MB 2.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.3/2.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.5/2.8 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.7/2.8 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.9/2.8 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.8 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.2/2.8 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.3/2.8 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.4/2.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.8/2.8 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.8/2.8 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.9/2.8 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.9/2.8 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.0/2.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.1/2.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.1/2.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.1/2.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.2/2.8 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.3/2.8 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.3/2.8 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.5/2.8 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.5/2.8 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.5/2.8 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.6/2.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.8/2.8 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.1 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 61.4/121.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.1/121.1 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: morfessor, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
      "Successfully installed indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.4.0 sphinx-rtd-theme-2.0.0 sphinxcontrib-jquery-4.1\n"
     ]
    }
   ],
   "source": [
    "# Downloading library\n",
    "\n",
    "!pip install indic-nlp-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CoyLxBvjTCli"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waqar\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVkflqT8bRdj"
   },
   "source": [
    "#### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "egDs_caZTY8q"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/Tamil_train_data.csv')\n",
    "test = pd.read_csv('data/Tamil_test_data.csv')\n",
    "valid = pd.read_csv('data/Tamil_valid_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cdjAnJzmTyHI"
   },
   "outputs": [],
   "source": [
    "train = train[train.tag != 'Not-Tamil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6gxDAUsAUNnm"
   },
   "outputs": [],
   "source": [
    "tags = {\"tag\":     {'Hope-Speech':0, 'None-of-the-above':7, 'Homophobia':1, 'Misandry':2,\n",
    "       'Counter-speech':3, 'Misogyny':4, 'Xenophobia':5, 'Transphobic':6}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RuE7vMtFUzkl"
   },
   "outputs": [],
   "source": [
    "train = train.replace(tags)\n",
    "valid = valid.replace(tags)\n",
    "test = test.replace(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qXEcRozRVmT_"
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train,valid],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hY6Lh9snVtUk",
    "outputId": "281ae61f-12c6-4978-b16f-1933a0ea358c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10227, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kJrc_HuytwFe"
   },
   "outputs": [],
   "source": [
    "train = train.drop(train[train['tag'] == 7].sample(frac=0.4).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "X8LFjK5iyUH1"
   },
   "outputs": [],
   "source": [
    "test_labels = pd.read_csv(\"data/Tamil_test_labels_data.csv\")\n",
    "\n",
    "test_labels = test_labels.replace(tags)\n",
    "test_labels = pd.merge(test_labels, test, on=['comments'])\n",
    "test_labels = test_labels.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f9J99E3IyZf_"
   },
   "outputs": [],
   "source": [
    "gt = []\n",
    "co = []\n",
    "for com in range(len(list(test_labels['comments']))):\n",
    "  if test_labels['comments'][com] in list(test['comments']):\n",
    "\n",
    "    gt.append(test_labels['tag'][com])\n",
    "    co.append(test_labels['comments'][com])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "701vIHx4yjCF",
    "outputId": "6847dd2d-7ec5-46cb-9d70-4f3e6d303a9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2555"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vEKU-mQct2Vy"
   },
   "outputs": [],
   "source": [
    "def oversample(df):\n",
    "    classes = [4,0,1,6,5]\n",
    "    most = 250\n",
    "    classes_list = []\n",
    "    for key in classes:\n",
    "        classes_list.append(df[df['tag'] == key]) \n",
    "    classes_sample = []\n",
    "    for i in range(len(classes_list)):\n",
    "        classes_sample.append(classes_list[i].sample(most, replace=True))\n",
    "    df_maybe = pd.concat(classes_sample)\n",
    "    final_df = pd.concat([df_maybe,df], axis=0)\n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Jrl2mv3ot7YK"
   },
   "outputs": [],
   "source": [
    "train = oversample(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSnr5z6MbH1o"
   },
   "source": [
    "#### Tokenization of the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ezKOgeFwU3gy"
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "def tokenize(s): return indic_tokenize.trivial_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7pysTr8JVHj8"
   },
   "outputs": [],
   "source": [
    "n = train.shape[0]\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "                      strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1)\n",
    "\n",
    "\n",
    "trn_term_doc = vec.fit_transform(train['comments'])\n",
    "test_term_doc = vec.transform(co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqkZ_XE2a6he"
   },
   "source": [
    "#### Training the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qzCweAheXmi6"
   },
   "outputs": [],
   "source": [
    "label_cols = ['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GvxdUq6JVaLN"
   },
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "test_x = test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oQEV7lVzVSzL"
   },
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "R9d49XB_WiDm"
   },
   "outputs": [],
   "source": [
    "import sklearn.svm as svm\n",
    "import sklearn.ensemble\n",
    "\n",
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = sklearn.ensemble.GradientBoostingClassifier()\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONkHmHTuWk_f",
    "outputId": "56b7a460-2a4f-4b37-d3cb-13e618356799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit tag\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(train[j])\n",
    "    preds = m.predict(test_x.multiply(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Srov1HIuu5jp",
    "outputId": "0a7314be-501b-4189-e490-5f060f6e652f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2555"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fv9cbwAeanmg"
   },
   "source": [
    "### Preparing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Rwy8XaVPXpDn"
   },
   "outputs": [],
   "source": [
    "test_labels = pd.read_csv(\"data/Tamil_test_labels_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3r5dd-dbixZ",
    "outputId": "5969bf83-b320-44e8-9d45-4e5f4675ace0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2559, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5av1jK3GX04z"
   },
   "outputs": [],
   "source": [
    "test_labels = test_labels.replace(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "N4A_xXtRj4Qv"
   },
   "outputs": [],
   "source": [
    "test_labels = test_labels.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgci5vyzbpyJ",
    "outputId": "c3b17074-8df1-41b6-d193-c59dfac68290"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2556, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg8TuNq-atqE"
   },
   "source": [
    "### Testing the model using unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fFyPVQ5NYQDR",
    "outputId": "ab33c919-6409-44a8-dfa0-131360c1c0c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.13      0.19        95\n",
      "           1       0.52      0.38      0.44        64\n",
      "           2       0.69      0.46      0.55       419\n",
      "           3       0.49      0.17      0.25       135\n",
      "           4       0.38      0.18      0.25       105\n",
      "           5       0.67      0.33      0.44       120\n",
      "           6       0.44      0.33      0.38        60\n",
      "           7       0.72      0.92      0.81      1557\n",
      "\n",
      "    accuracy                           0.69      2555\n",
      "   macro avg       0.53      0.36      0.41      2555\n",
      "weighted avg       0.66      0.69      0.65      2555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.metrics.classification_report(gt, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "E0ZBmymLYUfH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPoO+r4ywugeieONi6W5Ysp",
   "include_colab_link": true,
   "mount_file_id": "14UGW8HzpQaVx_aHdLy362N8i-hhGN7px",
   "name": "Gradient Boosting Classifier on sampled data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
